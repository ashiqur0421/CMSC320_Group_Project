{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqur0421/CMSC320_Group_Project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c1c8ee",
      "metadata": {
        "id": "01c1c8ee"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The Titanic sinking is one of the most historically significant disasters with over 1,500 passengers losing their lives on April 15, 1912. The Titanic dataset has been studied to understand how different factors influence the survivability of passengers. The dataset contains a lot of numerical and categorical information about each passenger, making it a great dataset for analysis.\n",
        "\n",
        "The goal of this project is to use machine learning techniques and train a Logistic Regression model to explore how different factors affected a passenger's chances of survival. Specifically, we want to answer the following questions:\n",
        "\n",
        "1.   What features (age, gender, passenger class, etc.) correlate most strongly with survival?\n",
        "\n",
        "      *   How does class, gender, and age affect survival?\n",
        "      *   Are there statistically significant differences in survival rates between 1st class vs. 3rd class, men vs. women, and children vs. adults?\n",
        "\n",
        "2.   Can we build a machine learning model to accurately predict whether a passenger survived based on their attributes?\n",
        "3.   How do precision, recall, and accuracy change as we vary the survival prediction cutoff?\n",
        "4.   How do the machine learning derived features' importance compare to our statistical findings?\n",
        "\n",
        "Understanding which passenger features correlate most strongly with survival on the Titanic is important because it allows us to verify historical narratives. For example, many of us have heard that women and children were given priority during evacuation, and we can verify this with statistical evidence from the dataset. Additionally, by identifying which features were most correlated with survival, we can better understand how social inequality, cabin class distribution, and other patterns shaped outcomes during this disaster.\n",
        "\n",
        "Evaluating whether our LR model can accurately predict survival is equally important because it demonstrates how well modern algorithms can learn from real data and highlights the challenges of classification when features are correlated or partially missing. This analysis strengthens our understanding of machine learning.\n",
        "\n",
        "Analyzing the precision, recall, and accuracy shows us the trade-offs our model has to make, and understanding this helps us choose the best cut-off for our case. Comparing machine learning features' importance with our statistical findings is also important because it tells us if different methods agree on which factors matter most and helps us understand how the model makes decisions.\n",
        "\n",
        "Together, these questions form a comprehensive exploration into the Titanic dataset by combining statistical inference, machine learning algorithms, and interpretability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9416539c",
      "metadata": {
        "id": "9416539c"
      },
      "source": [
        "# Data Curation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65aa009f",
      "metadata": {
        "id": "65aa009f"
      },
      "source": [
        "Source:  https://www.kaggle.com/datasets/yasserh/titanic-dataset\n",
        "\n",
        "The dataset contains passenger survival data of the Titanic, along with their identification (name and ticket number), and various factors that might have an effect on their survivability. These include their gender, age, relatives (who were aboard with them), their class (1st class, 2nd, or 3rd class), the fare rate they had to pay, and where they got on the ship from (Embarked).\n",
        "By doing the following exploratory analysis on the dataset, the relationships between passenger survivability and these factors were tested to see if any or all of them may have affected or even caused a passenger's survivability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qU2m8jYnMKOF",
      "metadata": {
        "id": "qU2m8jYnMKOF"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d1dbfa9698efe0",
      "metadata": {
        "id": "a3d1dbfa9698efe0"
      },
      "source": [
        "The Titanic dataset contains 891 entries and 12 features.\n",
        "\n",
        "Based on `titanic_df.info()`, the `Age` and `Cabin` columns are missing some values.\n",
        "\n",
        "There are no duplicate rows as indicated by `titanic_df.duplicated().sum()` being equal to zero."
      ]
    },
    {
      "cell_type": "code",
      "id": "caf469a6445a28f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "caf469a6445a28f6",
        "outputId": "c340fd88-0611-49f7-dc18-6fb7a1e34e45",
        "ExecuteTime": {
          "end_time": "2025-12-07T20:12:55.692228Z",
          "start_time": "2025-12-07T20:12:55.581646Z"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "#titanic_df = pd.read_csv(\"Titanic-Dataset.csv\")\n",
        "titanic_df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqur0421/CMSC320_Group_Project/refs/heads/main/Titanic-Dataset.csv\")\n",
        "print(\"Dataframe:\")\n",
        "display(titanic_df)\n",
        "print(\"Info:\")\n",
        "display(titanic_df.info())"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2572313977.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproportion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproportions_ztest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#titanic_df = pd.read_csv(\"Titanic-Dataset.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtitanic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/ashiqur0421/CMSC320_Group_Project/refs/heads/main/project.ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataframe:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitanic_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n"
          ]
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "id": "9cffc80293691efd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:35.311336Z",
          "start_time": "2025-12-07T19:56:35.260284Z"
        },
        "id": "9cffc80293691efd"
      },
      "source": [
        "print(\"Duplicated:\")\n",
        "print(titanic_df.duplicated())\n",
        "print(f\"Number of duplicated values: {titanic_df.duplicated().sum()}\")\n",
        "print(\"\\nDescribe:\")\n",
        "display(titanic_df.describe())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "a7608fa0356d99f2",
      "metadata": {
        "id": "a7608fa0356d99f2"
      },
      "source": [
        "We will not be using the `PassengerID` or `Name` columns, as we believe them to be largely irrelevant to the survival of a passenger; the `Cabin` column, due to its incredibly sparse nature (the vast majority of its values are `NaN`); nor the `Ticket` column (representing the ticket number of each passenger), because its values are largely incomprehensible, and we have many other features to work with already."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24c8e00165c42009",
      "metadata": {
        "id": "24c8e00165c42009"
      },
      "source": [
        "Below are some hypothesis tests we performed in the process of exploring our data. For all hypothesis testing, we chose a significance level of $\\alpha = 0.05$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b27f0af123fd3",
      "metadata": {
        "id": "a1b27f0af123fd3"
      },
      "source": [
        "## Survival vs. Passenger Class"
      ]
    },
    {
      "cell_type": "code",
      "id": "abea7acbdfd1881c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:35.784565Z",
          "start_time": "2025-12-07T19:56:35.655164Z"
        },
        "id": "abea7acbdfd1881c"
      },
      "source": [
        "contingency_table = pd.crosstab(titanic_df['Pclass'], titanic_df['Survived'])\n",
        "chi2_class, p_class, dof_class, _ = stats.chi2_contingency(contingency_table)\n",
        "print(contingency_table)\n",
        "print(f\"Chi-square: {chi2_class:.4g}  p-value: {p_class:.4g}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "fb933106cbf51c5b",
      "metadata": {
        "id": "fb933106cbf51c5b",
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:37.414394Z",
          "start_time": "2025-12-07T19:56:35.868528Z"
        }
      },
      "source": [
        "survive_rate_class = contingency_table[1] / contingency_table.sum(axis=1)\n",
        "x_values = [\"1st Class\", \"2nd Class\", \"3rd Class\"]\n",
        "survival = survive_rate_class.values\n",
        "plt.bar(x_values, survival)\n",
        "plt.title(\"Survival Rate vs. Passenger Class\")\n",
        "plt.ylabel(\"Survival Rate\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "7438b1bec37743b3",
      "metadata": {
        "id": "7438b1bec37743b3"
      },
      "source": [
        "From the contigency table, we see that there is a statistically significant relationship between passenger class and survival outcome. There appears to be an association between passenger class and whether a passenger survived the Titanic. First class passengers were much more likely to survive, and this makes logical sense because they had better access to lifeboats and were given priority. The p-value is less than 0.05, meaning we reject the null hypothesis and conclude that passenger class is strongly associated with survival on the Titanic."
      ]
    },
    {
      "cell_type": "code",
      "id": "484b40fdd503290a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:37.509712Z",
          "start_time": "2025-12-07T19:56:37.499657Z"
        },
        "id": "484b40fdd503290a"
      },
      "source": [
        "survival_num = contingency_table[1]\n",
        "total_counts = contingency_table.sum(axis=1)\n",
        "comparisons = [(1, 2),(1, 3), (2, 3)]\n",
        "print(\"Pairwise Z-tests for survival differences between passenger classes:\\n\")\n",
        "for i, j in comparisons:\n",
        "  print(\"Class \"f\"{i} vs. Class \"f\"{j}:\")\n",
        "  survival_btwn_classes = [survival_num[i], survival_num[j]]\n",
        "  total = [total_counts[i], total_counts[j]]\n",
        "  z, p = proportions_ztest(survival_btwn_classes, total)\n",
        "  print(f\"Z = {z:.4g}, p-value = {p:.4g}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "22b3e5bbffc957da",
      "metadata": {
        "id": "22b3e5bbffc957da"
      },
      "source": [
        "All of the p-values are far below 0.05, so we reject the null hypothesis for all comparisons of the passenger classes. So, each difference in survival between the classes (first vs. second, first vs. third, and second vs. third) is statistically significant. So, passenger class was a major factor that influenced survival."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_z1iUbMO6l8H",
      "metadata": {
        "id": "_z1iUbMO6l8H"
      },
      "source": [
        "## Survival vs. Passenger Fare"
      ]
    },
    {
      "cell_type": "code",
      "id": "YXLZfTE3D4QS",
      "metadata": {
        "id": "YXLZfTE3D4QS",
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:37.545711Z",
          "start_time": "2025-12-07T19:56:37.534305Z"
        }
      },
      "source": [
        "fare_survived = titanic_df[titanic_df['Survived'] == 1]['Fare']\n",
        "fare_died = titanic_df[titanic_df['Survived'] == 0]['Fare']\n",
        "\n",
        "# displaying summary statistics for both group\n",
        "print(\"----- Survived ----- \")\n",
        "print(fare_survived.describe())\n",
        "print(\"\\n\\n----- Not Survived ----- \")\n",
        "print(fare_died.describe())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "PHYdvx7A7g11",
      "metadata": {
        "id": "PHYdvx7A7g11"
      },
      "source": [
        "There are only two possible results for survivability: Survived or Died. So, these two groups are independent regarding themselves. <br>\n",
        "H0: Both groups have no difference in fare  <br>\n",
        "HA: Both groups have difference in fare"
      ]
    },
    {
      "cell_type": "code",
      "id": "GunBOeI87B9E",
      "metadata": {
        "id": "GunBOeI87B9E",
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:37.580432Z",
          "start_time": "2025-12-07T19:56:37.566966Z"
        }
      },
      "source": [
        "# unpaired t-test\n",
        "t_stat, p_value = stats.ttest_ind(fare_survived, fare_died, equal_var=False, alternative = 'two-sided')\n",
        "print(f\"unpaired_t test p_value: {p_value:.4g}\")\n",
        "\n",
        "# mann-whitney u test\n",
        "u, p_value = stats.mannwhitneyu(fare_survived, fare_died, alternative='two-sided')\n",
        "print(f\"mann-whitney u p value: {p_value:.4g}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "cF6hrKQRCKpE",
      "metadata": {
        "id": "cF6hrKQRCKpE"
      },
      "source": [
        "Based on the unpaired t-test, the p-value is $2.70  \\cdot 10^{-11}$ which is much lower than the significance level of 0.05. This means, we reject the null hypothesis meaning there was a signifant difference between survived and not-survived people's fare. On other words, fair did have an effect on the survivibility of the passesgeners.\n",
        "Since both group has outliers, we decided to do a mann-whitney u test. It also gives the similar conclusion with a p value of $4.55  \\cdot 10^{-22}$ which is much lower than significance level of 0.5. So, it similarly suggests that fair did have an effect on the survivibility of the passesgeners."
      ]
    },
    {
      "cell_type": "code",
      "id": "JYaODDpWDKlD",
      "metadata": {
        "id": "JYaODDpWDKlD",
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:37.790461Z",
          "start_time": "2025-12-07T19:56:37.660066Z"
        }
      },
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "plt.boxplot([fare_survived, fare_died], tick_labels = ['Survived', 'Not Survived'])\n",
        "plt.title(\"Fare vs Survivibility\")\n",
        "plt.ylabel(\"Fare\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "c1c96843f161a7fe",
      "metadata": {
        "id": "c1c96843f161a7fe"
      },
      "source": [
        "## Survival vs. Sex\n",
        "\n",
        "In the original dataset, `Sex` is a string feature. In order to use it for ML analysis, we need to convert it into a numerical feature. Thankfully, it is a binary variable, so we can simply assign `0` to `male` and `1` to `female`:"
      ]
    },
    {
      "cell_type": "code",
      "id": "7647d6c223282b0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:37.809827Z",
          "start_time": "2025-12-07T19:56:37.801859Z"
        },
        "id": "7647d6c223282b0"
      },
      "source": [
        "# Convert sex to ints\n",
        "def str_to_int(val):\n",
        "    if val == 'male':\n",
        "        return 0\n",
        "    elif val == 'female':\n",
        "        return 1\n",
        "    else:\n",
        "        return None\n",
        "titanic_df['Sex'] = titanic_df['Sex'].apply(str_to_int)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "81d579b8547263d9",
      "metadata": {
        "id": "81d579b8547263d9"
      },
      "source": [
        "Now we can perform the rest of our exploratory data analysis:"
      ]
    },
    {
      "cell_type": "code",
      "id": "67ef3dfc3874de39",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.057697Z",
          "start_time": "2025-12-07T19:56:37.828144Z"
        },
        "id": "67ef3dfc3874de39"
      },
      "source": [
        "contingency = pd.crosstab(titanic_df['Survived'], titanic_df['Sex'])\n",
        "print(contingency)\n",
        "fig, (a1, a2) = plt.subplots(1, 2)\n",
        "a1.bar(['Died', 'Survived'], contingency[0])\n",
        "a1.set_title(\"Men\")\n",
        "a2.bar(['Died', 'Survived'], contingency[1])\n",
        "a2.set_title(\"Women\")\n",
        "fig.tight_layout()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "f4823a6de3b26c02",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-26T21:29:31.651370Z",
          "start_time": "2025-10-26T21:29:31.649212Z"
        },
        "id": "f4823a6de3b26c02"
      },
      "source": [
        "The easiest test we can perform here is a simple chi-squared test. However, because our table is so small (2x2), we need to apply Yate's correction for continuity, which brings each observation 0.5 closer to the expected frequency before squaring when it computes the chi-squared test statistic. Thankfully, Scipy automatically detects and performs this correction for us:"
      ]
    },
    {
      "cell_type": "code",
      "id": "8a825d720f18799c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.101473Z",
          "start_time": "2025-12-07T19:56:38.097517Z"
        },
        "id": "8a825d720f18799c"
      },
      "source": [
        "chi2 = stats.chi2_contingency(contingency)\n",
        "print(\"Chi-squared test with Yate's correction for continuity:\")\n",
        "print(f\"Chi-squared test statistic: {chi2.statistic: .4g}\")\n",
        "print(f\"p-value: {chi2.pvalue: .4g}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "c46ec985c7d92c63",
      "metadata": {
        "id": "c46ec985c7d92c63"
      },
      "source": [
        "Our resulting p-value of $1.197 \\cdot 10^{-58}$ is clearly less than our significance level of 0.05.\n",
        "\n",
        "Because our sample size is so small, it's worth additionally performing Fisher's exact test, a statistical test usually reserved for small contingency tables known for being particularly conservative regarding the p-value:"
      ]
    },
    {
      "cell_type": "code",
      "id": "74767a6558e0844e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.173962Z",
          "start_time": "2025-12-07T19:56:38.166583Z"
        },
        "id": "74767a6558e0844e"
      },
      "source": [
        "fisher_exact_result = stats.fisher_exact(contingency, alternative=\"two-sided\")\n",
        "print(\"Fisher's exact test:\")\n",
        "print(f\"Prior odds ratio: {fisher_exact_result.statistic:.4g}\")\n",
        "print(f\"P-value: {fisher_exact_result.pvalue: .4g}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "6ba46d3ec5199c6a",
      "metadata": {
        "id": "6ba46d3ec5199c6a"
      },
      "source": [
        "Note that, even using Fisher's exact test, we still obtain a p-value of $6.464 \\cdot 10^{-60}$ significantly below our significance level of 0.05. There is clearly substantial evidence that the distribution of passengers who survived vs. died is not the same between men and women on the Titanic, which makes sense as women and children were given priority when boarding lifeboats.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65bebcd04b16808b",
      "metadata": {
        "id": "65bebcd04b16808b"
      },
      "source": [
        "## Survival vs. # siblings/spouses"
      ]
    },
    {
      "cell_type": "code",
      "id": "a47b025180de033c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.228607Z",
          "start_time": "2025-12-07T19:56:38.207141Z"
        },
        "id": "a47b025180de033c"
      },
      "source": [
        "sibsp_table = pd.crosstab(titanic_df['SibSp'], titanic_df['Survived'])\n",
        "chi2, p, dof, expected = stats.chi2_contingency(sibsp_table)\n",
        "print(\"SibSp vs Survived\")\n",
        "print(f\"Chi2: {chi2:.4g}\", f\"p-value: {p:.4g}\")\n",
        "print(\"Contingency Table:\\n\", sibsp_table, \"\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "2fade671e4160167",
      "metadata": {
        "id": "2fade671e4160167"
      },
      "source": [
        "From the contingency table, we see that there is a statistically significant relationship between the number of siblings/spouses aboard and survival outcome. Passengers with less siblings and spouses (SibSp is lower) had a lower chance of dying and higher chance of surviving compared to those with larger families. The Chi-squared test gives a p-value of approximately $1.56 \\cdot 10^{-6}$, which is far below 0.05. This means we reject the null hypothesis and conclude that SibSp is significantly associated with survival on the Titanic. It makes sense logically, as passengers with very large families may have had more difficulty escaping in time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5cc1f50793b070",
      "metadata": {
        "id": "b5cc1f50793b070"
      },
      "source": [
        "## Survival vs. # parents/children"
      ]
    },
    {
      "cell_type": "code",
      "id": "4722fef0351168e4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.264248Z",
          "start_time": "2025-12-07T19:56:38.247495Z"
        },
        "id": "4722fef0351168e4"
      },
      "source": [
        "parch_table = pd.crosstab(titanic_df['Parch'], titanic_df['Survived'])\n",
        "chi2, p, dof, expected = stats.chi2_contingency(parch_table)\n",
        "print(\"Parch vs Survived\")\n",
        "print(f\"Chi2: {chi2:.4g}\", f\"p-value: {p:.4g}\")\n",
        "print(\"Contingency Table:\\n\", parch_table, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "487302328af3cfdb",
      "metadata": {
        "id": "487302328af3cfdb"
      },
      "source": [
        "From the contingency table, we see that there is a statistically significant relationship between the number of parents/children aboard and survival outcome. Passengers traveling with fewer parents or children generally had a higher chance of surviving, whereas those with larger numbers of relatives were less likely to survive. The Chi-squared test gives a p-value of approximately $9.7 \\cdot 10^{-5}$, which is below 0.05, so we reject the null hypothesis. This suggests that traveling with many dependents may have made it more difficult to escape in time, impacting survival.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4421accbbd3c68",
      "metadata": {
        "id": "1e4421accbbd3c68"
      },
      "source": [
        "## Survival vs. Age\n",
        "\n",
        "`Age` has just under $20\\%$ of its values missing. Normally, a proportion of missing values like this would call for some advanced imputation techniques, but due to the simple nature of our logistic regression model, we can get away with median imputation:"
      ]
    },
    {
      "cell_type": "code",
      "id": "7f302123e933b169",
      "metadata": {
        "id": "7f302123e933b169",
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.294276Z",
          "start_time": "2025-12-07T19:56:38.288373Z"
        }
      },
      "source": [
        "# Fill MCAR with single imputing (median)\n",
        "titanic_df['Age'] = pd.to_numeric(titanic_df['Age'], errors='coerce').fillna(titanic_df['Age'].median())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "de84302a9bdeb7c1",
      "metadata": {
        "id": "de84302a9bdeb7c1"
      },
      "source": [
        "We can now proceed with our exploratory data analysis:"
      ]
    },
    {
      "cell_type": "code",
      "id": "534bf4324b950003",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.348175Z",
          "start_time": "2025-12-07T19:56:38.337933Z"
        },
        "id": "534bf4324b950003"
      },
      "source": [
        "age_survived = titanic_df[titanic_df[\"Survived\"] == 1][\"Age\"]\n",
        "age_not_survived = titanic_df[titanic_df[\"Survived\"] == 0][\"Age\"]\n",
        "# displaying summary statistics for both group\n",
        "print(\"----- Survived ----- \")\n",
        "print(age_survived.describe())\n",
        "print(\"\\n\\n----- Not Survived ----- \")\n",
        "print(age_not_survived.describe())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "567c14554784a353",
      "metadata": {
        "id": "567c14554784a353"
      },
      "source": [
        "H0: There is no meaningful difference between ages of those that survived and those that didn't.\n",
        "\n",
        "HA: There is a meaningful difference between ages of those that survived and those that didn't."
      ]
    },
    {
      "cell_type": "code",
      "id": "74438fa9be68c031",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.392626Z",
          "start_time": "2025-12-07T19:56:38.384098Z"
        },
        "id": "74438fa9be68c031"
      },
      "source": [
        "# unpaired t-test\n",
        "t_stat, p_value = stats.ttest_ind(age_survived, age_not_survived, equal_var=False, alternative = 'two-sided')\n",
        "print(f\"unpaired_t test p_value: {p_value:.4g}\")\n",
        "# mann-whitney u test\n",
        "u, p_value = stats.mannwhitneyu(fare_survived, age_not_survived, alternative='two-sided')\n",
        "print(f\"mann-whitney u p value: {p_value:.4g}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "5f772b93b627430d",
      "metadata": {
        "id": "5f772b93b627430d"
      },
      "source": [
        "The Mann-Whitney test gave a p-value of $3.99 \\cdot 10^{-2}$, which is under our significance level of .05. We reject the null hypothesis, suggesting statistically significant differences between the age distributions of survivors vs non-survivors.\n",
        "However, the t-test had a p-value of $5.83 \\cdot 10^{-2}$, which is over our significance level of .05, meaning we fail to reject the null hypothesis. This suggests that there is no statistical significance between the mean ages of those who survived and those who didn't\n",
        "So, the averages may be similar, but the distributions of survivors' vs. non-survivors' age is different. We reject the null hypothesis based on the Mann-Whitney U test, but fail to reject it based on the t-test."
      ]
    },
    {
      "cell_type": "code",
      "id": "4ddfa4dba2dcee6d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.515183Z",
          "start_time": "2025-12-07T19:56:38.414132Z"
        },
        "id": "4ddfa4dba2dcee6d"
      },
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "plt.boxplot([age_survived, age_not_survived], tick_labels = ['Survived', 'Not Survived'])\n",
        "plt.title(\"Age vs Survivability\")\n",
        "plt.ylabel(\"Age\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "203ca4b9bfcd16bd",
      "metadata": {
        "id": "203ca4b9bfcd16bd"
      },
      "source": [
        "## Survival vs. port of embarcation"
      ]
    },
    {
      "cell_type": "code",
      "id": "e8ce7a5a27d2a379",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:38.550848Z",
          "start_time": "2025-12-07T19:56:38.540866Z"
        },
        "id": "e8ce7a5a27d2a379"
      },
      "source": [
        "cont = pd.crosstab(titanic_df['Embarked'], titanic_df['Survived'])\n",
        "print(cont)\n",
        "chi2, p, dof, expected = stats.chi2_contingency(cont)\n",
        "print(\"Port of embarcation vs. Survived\")\n",
        "print(f\"Chi2: {chi2:.4g}\", f\"p-value: {p:.4g}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "c6f6397907eead6c",
      "metadata": {
        "id": "c6f6397907eead6c"
      },
      "source": [
        "As is clear from the contingency table and the chi-squared analysis, the port from which a passenger embarked does have an association with the survival rate of the passenger; specifically, the survival rate for a passenger who embarked from Southampton is much lower than the survival rate for a passenger from the other two ports.\n",
        "\n",
        "There are three ports from which passengers embarked on the titanic: Cherbourg (`C`), Queenstown (`Q`), and Southampton (`S`). We need to convert this categorical feature to a numeric feature. Due to the nature of our logistic regression model, we decided that the best way to do this would be to change each port to the survival rate of all passengers from that port. Specifically, we would assign `~0.337` to `S`, `~0.389` to `Q`, and `0.554` to `C`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f54de2",
      "metadata": {
        "id": "31f54de2"
      },
      "source": [
        "# Model Selection\n",
        "\n",
        "For our primary analysis, we have chosen to use a supervised classification model. Specifically, Logistic Regression to predict if a particular passenger survived based on their provided characteristics.\n",
        "\n",
        "Our target variable, Survived, is a binary value. This means using regression for a continuous value wouldnâ€™t fit because this target variable better aligns with a classification problem. An unsupervised approach, like clustering, would reveal certain patterns but would not answer the question of whether a passenger survived directly. So, with the existence of pre-labeled data for the outcome of each passenger, using a supervised classification approach makes the most sense.\n",
        "\n",
        "There are several options for classification models, but logistic regression is a great fit for several reasons\n",
        "\n",
        "- Models the probability of a binary event, such as survived or died. We are then able to tune the probability threshold to balance the number of fall positives vs. false negatives.\n",
        "- Our exploratory data analysis shows several features that have strong relationships with whether a passenger survived or not. These include Passenger Class, Gender, and Age. Logistic regression can handle multiple encoded categorical variables and continuous values relatively well.\n",
        "- Logistic regression is very interpretable and allows us to both classify passengers and also understand the underlying factors that contribute to survivability.\n",
        "\n",
        "These reasons make logistic regression an appropriate option to solve our classification problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2be7e963",
      "metadata": {
        "id": "2be7e963"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T19:56:39.029591Z",
          "start_time": "2025-12-07T19:56:38.628928Z"
        },
        "id": "fdcbbc349ebe0ae5"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "embarked_survival = titanic_df.groupby('Embarked')['Survived'].mean()\n",
        "titanic_df['Embarked'] = titanic_df['Embarked'].map(embarked_survival)\n",
        "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(titanic_df['Embarked'].median())\n",
        "X = titanic_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "y = titanic_df['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")"
      ],
      "id": "fdcbbc349ebe0ae5"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T20:44:38.828609Z",
          "start_time": "2025-12-07T20:44:38.742841Z"
        },
        "id": "7f2de823e15163af"
      },
      "cell_type": "code",
      "source": [
        "confidence_scores = model.decision_function(X_test)\n",
        "events = np.array(sorted([*zip(confidence_scores, y_test)]))\n",
        "cutoff, tp, fp, tn, fn = [0], [0], [0], [0], [0]\n",
        "for event in events:\n",
        "    if event[1]:\n",
        "        tp[0] += 1\n",
        "    else:\n",
        "        fp[0] += 1\n",
        "def logistic(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "for event in events:\n",
        "    cutoff.append(logistic(event[0]))\n",
        "    if event[1]:\n",
        "        tp.append(tp[-1] - 1)\n",
        "        fn.append(fn[-1] + 1)\n",
        "        fp.append(fp[-1])\n",
        "        tn.append(tn[-1])\n",
        "    else:\n",
        "        fp.append(fp[-1] - 1)\n",
        "        tn.append(tn[-1] + 1)\n",
        "        tp.append(tp[-1])\n",
        "        fn.append(fn[-1])\n",
        "cutoff, tp, fp, tn, fn = np.array(cutoff), np.array(tp), np.array(fp), np.array(tn), np.array(fn)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(cutoff, tp, label=\"tp\")\n",
        "ax.plot(cutoff, fp, label=\"fp\")\n",
        "ax.plot(cutoff, tn, label=\"tn\")\n",
        "ax.plot(cutoff, fn, label=\"fn\")\n",
        "ax.axvline(0.5, c = 'k', ls=\"--\")\n",
        "ax.set_xlabel(\"Probability cutoff\")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "fig.suptitle(\"TP, FP, TN, and FN vs. probability cutoff\")\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "fig.tight_layout()"
      ],
      "id": "7f2de823e15163af",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-07T20:44:50.244649Z",
          "start_time": "2025-12-07T20:44:50.169372Z"
        },
        "id": "53c0c3f7d2dbf298"
      },
      "cell_type": "code",
      "source": [
        "accuracy = (tp + tn) / len(X_test)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(cutoff, accuracy, label=\"accuracy\")\n",
        "ax.plot(cutoff, precision, label=\"precision\")\n",
        "ax.plot(cutoff, recall, label=\"recall\")\n",
        "ax.axvline(0.5, c = 'k', ls=\"--\")\n",
        "ax.set_xlabel(\"Probability cutoff\")\n",
        "ax.set_ylabel(\"Proportion\")\n",
        "fig.suptitle(\"Accuracy, Precision, and Recall vs. Probability cutoff\")\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "fig.tight_layout()"
      ],
      "id": "53c0c3f7d2dbf298",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feature_names = X.columns\n",
        "coeffs = model.coef_[0]\n",
        "coeff_data = []\n",
        "\n",
        "for i in range(len(feature_names)):\n",
        "    coeff_data.append({'Feature': feature_names[i],'Coeff': coeffs[i]})\n",
        "\n",
        "importance_df = pd.DataFrame(coeff_data)\n",
        "plt.bar(importance_df['Feature'], importance_df['Coeff'])\n",
        "plt.title(\"Feature's Coefficient Weight\")\n",
        "plt.ylabel(\"Coefficient Value\")\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9zu3VE-J4Ib5"
      },
      "id": "9zu3VE-J4Ib5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature importance graph shows that sex is the strongest predictor of survival, followed by passenger class. This aligns with historical accounts because women and 1st class passengers were much more likely to survive since they were given priority. It also makes sense that passenger class has a negative coefficient because as class number increases from 1st to 3rd class, the probability of survival decreases."
      ],
      "metadata": {
        "id": "fOmTYUp84KuD"
      },
      "id": "fOmTYUp84KuD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold Cross Validation\n",
        "In order to gain a better understanding of model performance with different arrangements of data, we can use k-fold cross-validation.\n",
        "\n"
      ],
      "metadata": {
        "id": "RTSUMUeB3nP-"
      },
      "id": "RTSUMUeB3nP-"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Perform k=5 k-fold cross validation\n",
        "k = 5\n",
        "kfold = KFold(n_splits = k, shuffle = True, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=kfold, scoring=\"accuracy\")\n",
        "\n",
        "# Display accuracy and mean scores\n",
        "print(f\"Accuracy of folds: {scores}\")\n",
        "\n",
        "avg_acc = np.mean(scores)\n",
        "print(f\"Average Accuracy: {avg_acc:.2f}\")"
      ],
      "metadata": {
        "id": "3OtMrZX-3m9m"
      },
      "id": "3OtMrZX-3m9m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Our first model that used a single train/test split has an accuracy of 0.804. A more reliable estimate can be found by found by using k-fold cross validation. The mean accuracy when k=5 was 0.79, which is extremely close to the original model's accuracy of 0.804.\n",
        "\n",
        "This small difference suggests the initial model, while slightly better, is within performance expectations for the real world. Additional model complexity is likely unneeded since performance gains would be marginal. These results show the model already generalizes well."
      ],
      "metadata": {
        "id": "F9Cdk-vD3vbo"
      },
      "id": "F9Cdk-vD3vbo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Insight and Conclussion\n",
        "\n",
        "Based on the weights of the model of 81% accuracy, it's clear that sex (gender) is the most accurate predictor of the surviability of a passenger boarding Titanic. On contorary, their class seems to have the least impact on the surviability. The prominance of sex as the predictor indicates that contemporary social norm of protecting women. However, upon a test between the relationship of sex and passenger class, it is apparent that socioeconomic status does have an impact on those who survived."
      ],
      "metadata": {
        "id": "7aBJ2NAY41i0"
      },
      "id": "7aBJ2NAY41i0"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_group(sex, pclass):\n",
        "    row = pd.DataFrame([{         # a synthetic passenger\n",
        "        'Pclass': pclass,\n",
        "        'Sex': 1 if sex=='female' else 0,\n",
        "        'Age': titanic_df[\"Age\"].median(),\n",
        "        'SibSp': 0,\n",
        "        'Parch': 0,\n",
        "        'Fare': titanic_df[\"Fare\"].median(),\n",
        "        'Embarked': titanic_df[\"Embarked\"].median()\n",
        "    }])\n",
        "    return model.predict_proba(row)[0][1]\n",
        "\n",
        "print(\"1st-class woman:\", predict_group('female', 1))\n",
        "print(\"3rd-class woman:\", predict_group('female', 3))\n",
        "print(\"1st-class man:\",   predict_group('male', 1))\n",
        "print(\"3rd-class man:\",   predict_group('male', 3))"
      ],
      "metadata": {
        "id": "JDcPg-Fy493I"
      },
      "id": "JDcPg-Fy493I",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}